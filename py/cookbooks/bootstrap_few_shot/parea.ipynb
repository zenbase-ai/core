{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fef1f3269ab9d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import the Zenbase Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce565be4f08da1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        raise\n",
    "\n",
    "def install_packages(packages):\n",
    "    for package in packages:\n",
    "        install_package(package)\n",
    "\n",
    "try:\n",
    "    # Check if running in Google Colab\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install the zenbase package if running in Google Colab\n",
    "    # install_package('zenbase')\n",
    "    # Install the zenbse package from a GitHub branch if running in Google Colab\n",
    "    install_package('git+https://github.com/zenbase-ai/lib.git@main#egg=zenbase&subdirectory=py')\n",
    "\n",
    "    # List of other packages to install in Google Colab\n",
    "    additional_packages = [\n",
    "        'python-dotenv',\n",
    "        'parea-ai==0.2.164',\n",
    "        'openai',\n",
    "        'langchain',\n",
    "        'langchain_openai'\n",
    "    ]\n",
    "    \n",
    "    # Install additional packages\n",
    "    install_packages(additional_packages)\n",
    "\n",
    "# Now import the zenbase library\n",
    "try:\n",
    "    import zenbase\n",
    "except ImportError as e:\n",
    "    print(\"Failed to import zenbase: \", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c63173923a6209",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Configure the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"PAREA_API_KEY\"] = \"...\"\n",
    "\n",
    "load_dotenv(Path(\"../../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc2001d5d4cf98",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3ed902652dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b39159e4fe92c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f32dc5445e19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from parea import Parea, trace\n",
    "\n",
    "parea = Parea()\n",
    "openai = OpenAI()\n",
    "\n",
    "parea.wrap_openai_client(openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d4f2603406a40",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now, you probably already have some LLM code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9aa1c663f327c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## And let's say you have an eval function like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88427413505a7e69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from parea.schemas import Log, EvaluationResult\n",
    "\n",
    "def score_answer_with_json(log: Log) -> EvaluationResult:\n",
    "    if log.target:\n",
    "        output = str(expand_nested_json(log.output)[\"answer\"])\n",
    "        target = log.target.split(\"#### \")[-1]\n",
    "        return EvaluationResult(\"correctness\", int(output == target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945d61bfdec68e0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It could use the OpenAI SDK, LangChain, or anything really. But it looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b60c47eb2b2a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@trace(eval_funcs=[score_answer_with_json])\n",
    "def solver(inputs):\n",
    "    if isinstance(inputs, str):\n",
    "        inputs = expand_nested_json(inputs)\n",
    "    \n",
    "    plan = planner_chain(inputs)\n",
    "    operation = operation_finder({\n",
    "        \"plan\": plan[\"plan\"],\n",
    "        \"question\": inputs[\"question\"],\n",
    "    })\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Solve the given problem using the provided plan and operation. Return only the final numerical answer in JSON format.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {inputs['question']}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Plan: {plan['plan']}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Required mathematical operation: {operation['operation']}\"},\n",
    "        {\"role\": \"user\", \"content\": \"Provide the final answer as a number in JSON format: {\\\"answer\\\": YOUR_NUMERICAL_ANSWER}\"},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    answer = json.loads(response.choices[0].message.content)\n",
    "    return {\"answer\": answer[\"answer\"]}\n",
    "\n",
    "@trace\n",
    "def planner_chain(inputs):\n",
    "    if isinstance(inputs, str):\n",
    "        inputs = expand_nested_json(inputs)\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Create a step-by-step plan to solve the given math problem. Return the plan as a JSON object with a 'plan' key.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": inputs[\"question\"]},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    answer = json.loads(response.choices[0].message.content)\n",
    "    return {\"plan\": answer[\"plan\"]}\n",
    "\n",
    "@trace\n",
    "def operation_finder(inputs):\n",
    "    if isinstance(inputs, str):\n",
    "        inputs = expand_nested_json(inputs)\n",
    "        \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Identify the primary mathematical operation needed to solve the problem based on the given question and plan. Use simple operations like addition, subtraction, multiplication, or division. Return the operation as a JSON object with an 'operation' key.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {inputs['question']}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Plan: {inputs['plan']}\"},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    answer = json.loads(response.choices[0].message.content)\n",
    "    return {\"operation\": answer[\"operation\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cb0deaec6c657",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6aff46721d494",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver({\"question\": \"What is 2+2?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6f06c65d6014",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Then you're probably evaluating like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea722547c504c49f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_kwargs = dict(\n",
    "    data=\"GSM8K_test_set_parea_dataset_2iyvfWLaZFAhZ6V6NGa8gp3WKBx\",\n",
    "    n_workers=1,\n",
    ")\n",
    "\n",
    "parea.experiment(\n",
    "    name=\"wibbly-wobbly\",\n",
    "    func=solver,\n",
    "    **experiment_kwargs\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a73ea95aabe4d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " # Now, how can we optimize this score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c6e3bde502cd9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## First, initialize the Zenbase ZenbaseTracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a86f1b472777ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from zenbase.core.managers import ZenbaseTracer\n",
    "\n",
    "zenbase_tracer = ZenbaseTracer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874849f1818a1fb2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## For Lunary, we have to update our eval function a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c92f75ca32af0d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_answer_with_json(log: Log) -> EvaluationResult:\n",
    "    if log.target:\n",
    "        output = str(expand_nested_json(log.output)[\"answer\"])\n",
    "        target = log.target.split(\"#### \")[-1]\n",
    "        return EvaluationResult(\"correctness\", int(output == target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e00261655b612d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hook up Zenbase to your functions\n",
    "\n",
    "1. Use the `zenbase_tracer` decorator.\n",
    "2. Change function inputs to request\n",
    "3. Use request's `zenbase.task_demos` to get the few-shot examples for the task and add them however you would like into your prompt.\n",
    "4. If you need to use just a few examples, you can use `request.zenbase.task_demos[:2]` to get the first two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75125e8ad065532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest\n",
    "import json\n",
    "from zenbase.utils import expand_nested_json\n",
    "from parea.schemas import EvaluationResult\n",
    "import openai\n",
    "\n",
    "@zenbase_tracer # it is 1\n",
    "@trace(eval_funcs=[score_answer_with_json])\n",
    "def solver(request: LMRequest): # it is 2\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Solve the given problem using the provided plan and operation. Return only the final numerical answer in JSON format and the key of answer.\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for demo in request.zenbase.task_demos: # it is 3\n",
    "        messages += [\n",
    "            {\"role\": \"user\", \"content\": f\"Example Question: {str(demo.inputs)}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Example Answer: {str(demo.outputs)}\"},\n",
    "        ]\n",
    "\n",
    "    plan = planner_chain(request.inputs)\n",
    "    the_plan = plan[\"plan\"]\n",
    "    the_operation = operation_finder(\n",
    "        {\n",
    "            \"plan\": the_plan,\n",
    "            \"question\": request.inputs[\"question\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Question: {request.inputs['question']}\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Plan: {the_plan}\"})\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": f\"Mathematical Operation needed: {the_operation['operation']}\"}\n",
    "    )\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": \"Provide the answer as a number in JSON format.\"}\n",
    "    )\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    answer = json.loads(response.choices[0].message.content)\n",
    "    return {\"answer\": answer[\"answer\"]}\n",
    "\n",
    "@zenbase_tracer # it is 1\n",
    "@trace\n",
    "def planner_chain(request: LMRequest): # it is 2\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Create a step-by-step plan to solve the given math problem. Return the plan as a JSON object with a 'plan' key.\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    if request.zenbase.task_demos: # it is 3\n",
    "        for demo in request.zenbase.task_demos[:2]: # it is 4\n",
    "            messages += [\n",
    "                {\"role\": \"user\", \"content\": str(demo.inputs)},\n",
    "                {\"role\": \"assistant\", \"content\": str(demo.outputs)},\n",
    "            ]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": request.inputs.get(\"question\", \"What is 2 + 2?\")})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    answer = json.loads(response.choices[0].message.content)\n",
    "    return {\"plan\": \" \".join(answer[\"plan\"])}\n",
    "\n",
    "@zenbase_tracer # it is 1\n",
    "@trace\n",
    "def operation_finder(request: LMRequest): # it is 2\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Identify the primary mathematical operation needed to solve the problem based on the given question and plan. Use simple operations like addition, subtraction, multiplication, or division. Return the operation as a JSON object with an 'operation' key.\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    if request.zenbase.task_demos: # it is 3\n",
    "        for demo in request.zenbase.task_demos[:2]: # it is 4\n",
    "            messages += [\n",
    "                {\"role\": \"user\", \"content\": f\"Input: {str(demo.inputs)}\"},\n",
    "                {\"role\": \"assistant\", \"content\": str(demo.outputs)},\n",
    "            ]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Question: {request.inputs['question']}\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Plan: {request.inputs['plan']}\"})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    answer = json.loads(response.choices[0].message.content)\n",
    "    return {\"operation\": answer[\"operation\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e7c107059cbdc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Now we can optimize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acc47fa9f26e62",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Set up your optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935c1126e7e18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenbase.optim.metric.bootstrap_few_shot import BootstrapFewShot\n",
    "from zenbase.adaptors.parea import ZenParea\n",
    "\n",
    "zen_parea_adaptor = ZenParea(parea)\n",
    "\n",
    "TRAIN_SET = \"GSM8K_train_set_parea_dataset_2inu4fpM2Q5zIo0JDbtXZOeaG9Y\"\n",
    "TEST_SET = \"GSM8K_test_set_parea_dataset_2inu4fT1X5IZKj361H21BbD2Mc4\"\n",
    "VALIDATION_SET = \"GSM8K_validation_set_parea_dataset_2inu3r5jX6ruauOovt2rf5L5LHG\"\n",
    "SHOTS = 2\n",
    "SAMPLES = 2\n",
    "\n",
    "evaluator_kwargs = dict(\n",
    "    p=parea,\n",
    "    n_workers=1,\n",
    ")\n",
    "\n",
    "bootstrap_few_shot = BootstrapFewShot(\n",
    "    shots=SHOTS,\n",
    "    training_set=TRAIN_SET,\n",
    "    test_set=TEST_SET,\n",
    "    validation_set=VALIDATION_SET,\n",
    "    evaluator_kwargs=evaluator_kwargs,\n",
    "    zen_adaptor=zen_parea_adaptor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71255e2b5ef16a58",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Do the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d309dfbb96cfd0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Empty the traces\n",
    "zenbase_tracer.all_traces = {}\n",
    "# Run the optimization\n",
    "best_fn, candidates = bootstrap_few_shot.perform(\n",
    "    solver,\n",
    "    samples=SAMPLES,\n",
    "    rounds=1,\n",
    "    trace_manager=zenbase_tracer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2782c6151deacb65",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Use your optimized function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03caab067b16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenbase_tracer.all_traces = {}\n",
    "best_fn({\"question\": \"What is 2 + 2?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede6295bdd0795a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Introspect function traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920366cf248a74c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function_traces = [v for k, v in zenbase_tracer.all_traces.items()][0][\"optimized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78460ac70c02e67",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check the optimized parameters for solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1238b2f9348cc5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"solver\"][\"args\"][\"request\"].zenbase.task_demos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db4456a0be1991",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check the optimized parameters for planner_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba62b852467ab96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"planner_chain\"][\"args\"][\"request\"].zenbase.task_demos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c579a40d3e079",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check the optimized parameters for operation_finder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ba2abfd65d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"operation_finder\"][\"args\"][\"request\"].zenbase.task_demos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd52b6486c075b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## How to save the function and load it later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0cc848da4d9dbb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save the optimized function args to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946162598f36aaf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstrap_few_shot.save_optimizer_args(\"bootstrap_few_shot_args.zenbase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe41d4ce2ea2188f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the optimized function args with the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be759cb31c41c35f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bootstrap_few_shot.save_optimizer_args(\"bootstrap_few_shot_args.zenbase\")\n",
    "\n",
    "optimized_function = bootstrap_few_shot.load_optimizer_and_function(\"bootstrap_few_shot_args.zenbase\", solver, zenbase_tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad009e26d106c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Use the loaded function and make sure it loaded the demos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15c14a9d31ef17",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zenbase_tracer.all_traces = {}\n",
    "optimized_function({\"question\": \"If I have 30% of shares, and Mo has 24.5% of shares, how many of our 10M shares are unassigned?\"})\n",
    "function_traces = [v for k, v in zenbase_tracer.all_traces.items()][0][\"optimized\"]\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(function_traces[\"solver\"][\"args\"][\"request\"].zenbase.task_demos)\n",
    "pprint(function_traces[\"planner_chain\"][\"args\"][\"request\"].zenbase.task_demos)\n",
    "pprint(function_traces[\"operation_finder\"][\"args\"][\"request\"].zenbase.task_demos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
