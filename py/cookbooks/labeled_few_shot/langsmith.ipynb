{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import the Zenbase Library"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6205bbdee427dc05"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        raise\n",
    "\n",
    "def install_packages(packages):\n",
    "    for package in packages:\n",
    "        install_package(package)\n",
    "\n",
    "try:\n",
    "    # Check if running in Google Colab\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install the zenbase package if running in Google Colab\n",
    "    # install_package('zenbase')\n",
    "    # Install the zenbse package from a GitHub branch if running in Google Colab\n",
    "    install_package('git+https://github.com/zenbase-ai/lib.git@main#egg=zenbase&subdirectory=py')\n",
    "\n",
    "    # List of other packages to install in Google Colab\n",
    "    additional_packages = [\n",
    "        'python-dotenv',\n",
    "        'langsmith[vcr]',\n",
    "        'openai',\n",
    "        'langchain',\n",
    "        'langchain_openai'\n",
    "    ]\n",
    "    \n",
    "    # Install additional packages\n",
    "    install_packages(additional_packages)\n",
    "\n",
    "# Now import the zenbase library\n",
    "try:\n",
    "    import zenbase\n",
    "except ImportError as e:\n",
    "    print(\"Failed to import zenbase: \", e)\n",
    "    raise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44750b55e512a6cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure the Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1193acc581303981"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1377617ec4c1781f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:51.864719Z",
     "start_time": "2024-07-03T16:43:51.857821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "load_dotenv(Path(\"../../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808bae4c98be5c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:52.393332Z",
     "start_time": "2024-07-03T16:43:52.390477Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cee844fa658a944d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langsmith.wrappers import wrap_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openai = wrap_openai(OpenAI())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac7e02f5bbfa9090"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What you already have should look like below:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a744e7987460d8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your OpenAI Call should look like this with LangChain (It could be with OpenAI too, doesn't matter)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa8f7924e561cd7f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49d5afd7ed94163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:52.992476Z",
     "start_time": "2024-07-03T16:43:52.940404Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langsmith import traceable\n",
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "\n",
    "# Define your LLM function\n",
    "@traceable\n",
    "def openai_json_response(inputs: dict) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples. Think step by step. Respond with a JSON object with a key of 'answer'.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": json.dumps(inputs)}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your Scoring Function should look like this:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3456dcab91b57b69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define your Langsmith evaluator\n",
    "def score_answer(run: Run, example: Example):\n",
    "    match (answer := run.outputs[\"answer\"]):\n",
    "        case int():\n",
    "            output = str(answer).strip()\n",
    "        case str():\n",
    "            output = answer.split(\"#### \")[-1].strip()\n",
    "    target = example.outputs[\"answer\"].split(\"#### \")[-1].strip()\n",
    "    return {\n",
    "        \"key\": \"correctness\",\n",
    "        \"score\": int(output == target),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "118471eb8f8eacc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your Evaluation should look like this:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a15f922cf8bc11c7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269ce9c328f8e5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:57.175237Z",
     "start_time": "2024-07-03T16:43:53.749824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'spotless-plane-52' at:\n",
      "https://smith.langchain.com/o/f145e0fe-631c-5153-984d-08acb624f83e/datasets/ab14f6ad-3e00-43b8-9ad6-3ce6bdb510f0/compare?selectedSessions=6bc92b05-dc54-4550-adb1-b5089251b497\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25fdf7d216464ee38e27202b8a0214fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<ExperimentResults spotless-plane-52>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using LangSmith\n",
    "from langsmith import Client, evaluate\n",
    "\n",
    "langsmith = Client()\n",
    "evalset = list(langsmith.list_examples(dataset_name=\"GSM8K_test_set_langsmith_dataset_2ii5SKBzVHu3UVUmiFIxFxSvsFm\"))\n",
    "\n",
    "evaluate_kwargs = dict(\n",
    "    data=evalset,\n",
    "    evaluators=[score_answer],\n",
    "    client=langsmith,\n",
    "    max_concurrency=2,\n",
    ")\n",
    "\n",
    "evaluate(openai_json_response, **evaluate_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How you should do the few-shot learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "586d7beecb52712c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rewrite your langchain_chain function to use the `zenbase` decorators"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69d3f6b9e7aeaf4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9592f3913f694364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:45:27.632741Z",
     "start_time": "2024-07-03T16:45:27.625464Z"
    }
   },
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest, deflm\n",
    "\n",
    "# Wrap your existing chain with @deflm and take in a `LMRequest` object\n",
    "# An LMRequest has the inputs for your chain and has a `zenbase` attribute.\n",
    "# This `zenbase` attribute includes the fields that Zenbase optimises.\n",
    "\n",
    "# LMRequest.inputs => LM function inputs\n",
    "# LMRequest.zenbase => optimized LLM params\n",
    "\n",
    "@deflm\n",
    "@traceable\n",
    "def openai_json_response(request: LMRequest) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples. Think step by step. Respond with a JSON object.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            {\"role\": \"user\", \"content\": json.dumps(demo.inputs)},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(demo.outputs)},\n",
    "        ]\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(request.inputs)})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimize the few-shot learning\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b15d7de0dc561c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define your optimizer:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1fd6425163b8fe"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c996174108b0981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:46:11.809431Z",
     "start_time": "2024-07-03T16:46:03.494083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'zenbase-right-sized-next-55ecd2a9' at:\n",
      "https://smith.langchain.com/o/f145e0fe-631c-5153-984d-08acb624f83e/datasets/ab14f6ad-3e00-43b8-9ad6-3ce6bdb510f0/compare?selectedSessions=945be100-b92b-49fd-9e0d-81950c8c5ce6\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88c89d337d404be186b3f6a529847823"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'zenbase-persevering-5thgeneration-7b5c3289' at:\n",
      "https://smith.langchain.com/o/f145e0fe-631c-5153-984d-08acb624f83e/datasets/ab14f6ad-3e00-43b8-9ad6-3ce6bdb510f0/compare?selectedSessions=d42ddd91-5cb0-40ba-8128-3ec0591380aa\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2ff9ce72f024d319e7d4e484ff2ea79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zenbase.adaptors.langchain import ZenLangSmith\n",
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "\n",
    "demoset = ZenLangSmith.examples_to_demos(\n",
    "    langsmith.list_examples(dataset_name=\"GSM8K_train_set_langsmith_dataset_2ii5SPh2qGRjlCzFIkp8d8qcKhH\")\n",
    ")\n",
    "optimizer = LabeledFewShot(demoset=demoset, shots=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform the optimization\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71e9238ee2d00c5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_fn, candidates, _ = optimizer.perform(\n",
    "    # Pass deflm decorated function\n",
    "    openai_json_response,\n",
    "    # Exactly the same as what you are passing to your evaluate function\n",
    "    evaluator=ZenLangSmith.metric_evaluator(**evaluate_kwargs),\n",
    "    samples=2,\n",
    "    rounds=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "793d1783fbb60b16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the best function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3dfbf0752510f23"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da6e5476084d83fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:46:17.878281Z",
     "start_time": "2024-07-03T16:46:14.375394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'answer': 'I have 30% shares which is 30/100 * 10M = <<30/100*10>>3000000 shares.\\nMo has 24.5% shares which is 24.5/100 * 10M = <<24.5/100*10>>2450000 shares.\\nTogether we have 3000000 + 2450000 = <<3000000+2450000=5450000>>5450000 shares.\\nSo, unassigned shares are 10M - 5450000 = <<10000000-5450000=4550000>>4550000 shares.\\n#### 4550000'}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can use your zenbase fn\n",
    "best_fn({\"question\": \"If I have 30% of shares, and Mo has 24.5% of shares, how many of our 10M shares are unassigned?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect the best function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3fa845a1e2f46a0"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "280bbbc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:46:20.065345Z",
     "start_time": "2024-07-03T16:46:20.060477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(LMDemo(inputs={'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'}, outputs={'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}, original_object=Example(dataset_id=UUID('0a09e04d-e9b7-4684-8a8c-aa603af76146'), inputs={'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'}, outputs={'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}, metadata=None, id=UUID('685a1ba1-9e26-4495-a17a-7efcfcc04dc9'), created_at=datetime.datetime(2024, 7, 2, 22, 49, 15, 568348, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 7, 2, 22, 49, 15, 568348, tzinfo=datetime.timezone.utc), runs=[], source_run_id=None)),\n LMDemo(inputs={'question': 'James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?'}, outputs={'answer': 'He writes each friend 3*2=<<3*2=6>>6 pages a week\\nSo he writes 6*2=<<6*2=12>>12 pages every week\\nThat means he writes 12*52=<<12*52=624>>624 pages a year\\n#### 624'}, original_object=Example(dataset_id=UUID('0a09e04d-e9b7-4684-8a8c-aa603af76146'), inputs={'question': 'James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?'}, outputs={'answer': 'He writes each friend 3*2=<<3*2=6>>6 pages a week\\nSo he writes 6*2=<<6*2=12>>12 pages every week\\nThat means he writes 12*52=<<12*52=624>>624 pages a year\\n#### 624'}, metadata=None, id=UUID('ce11c928-84ea-4ad1-b26e-22befee8cc0f'), created_at=datetime.datetime(2024, 7, 2, 22, 49, 15, 568348, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 7, 2, 22, 49, 15, 568348, tzinfo=datetime.timezone.utc), runs=[], source_run_id=None)),\n LMDemo(inputs={'question': 'Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?'}, outputs={'answer': \"In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\\nBetty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\\nThis means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\\n#### 5\"}, original_object=Example(dataset_id=UUID('0a09e04d-e9b7-4684-8a8c-aa603af76146'), inputs={'question': 'Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?'}, outputs={'answer': \"In the beginning, Betty has only 100 / 2 = $<<100/2=50>>50.\\nBetty's grandparents gave her 15 * 2 = $<<15*2=30>>30.\\nThis means, Betty needs 100 - 50 - 30 - 15 = $<<100-50-30-15=5>>5 more.\\n#### 5\"}, metadata=None, id=UUID('d8dadc4f-991c-45d0-b04b-a62ca2cbef0a'), created_at=datetime.datetime(2024, 7, 2, 22, 49, 15, 568348, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 7, 2, 22, 49, 15, 568348, tzinfo=datetime.timezone.utc), runs=[], source_run_id=None)))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fn.zenbase.task_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the best function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c3e0c279f2c40"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "622d32eb538487a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:46:21.889909Z",
     "start_time": "2024-07-03T16:46:20.968913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'answer': '4'}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "openai_json_response.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "openai_json_response({\"question\": \"What is 2 + 2?\"}) # uses the best few-shot demos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
