{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import the Zenbase Library\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        raise\n",
    "\n",
    "def install_packages(packages):\n",
    "    for package in packages:\n",
    "        install_package(package)\n",
    "\n",
    "try:\n",
    "    # Check if running in Google Colab\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install the zenbase package if running in Google Colab\n",
    "    # install_package('zenbase')\n",
    "    # Install the zenbse package from a GitHub branch if running in Google Colab\n",
    "    install_package('git+https://github.com/zenbase-ai/lib.git@main#egg=zenbase&subdirectory=py')\n",
    "\n",
    "    # List of other packages to install in Google Colab\n",
    "    additional_packages = [\n",
    "        'python-dotenv',\n",
    "        'lunary',\n",
    "        'openai',\n",
    "        'langchain',\n",
    "        'langchain_openai'\n",
    "    ]\n",
    "    \n",
    "    # Install additional packages\n",
    "    install_packages(additional_packages)\n",
    "\n",
    "# Now import the zenbase library\n",
    "try:\n",
    "    import zenbase\n",
    "except ImportError as e:\n",
    "    print(\"Failed to import zenbase: \", e)\n",
    "    raise"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T19:41:30.245361Z",
     "start_time": "2024-07-05T19:41:30.182742Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configure the Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:34:58.927773Z",
     "start_time": "2024-07-05T19:34:58.912611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"LUNARY_PUBLIC_KEY\"] = \"...\"\n",
    "\n",
    "load_dotenv(Path(\"../../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:34:58.933451Z",
     "start_time": "2024-07-05T19:34:58.929781Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:35:01.044166Z",
     "start_time": "2024-07-05T19:34:58.934749Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import lunary\n",
    "\n",
    "openai = OpenAI()\n",
    "lunary.monitor(openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What you already have should look like below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your OpenAI Call should look like this with LangChain (It could be with OpenAI too, doesn't matter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:35:01.052688Z",
     "start_time": "2024-07-05T19:35:01.046927Z"
    }
   },
   "outputs": [],
   "source": [
    "def langchain_chain(inputs):\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    "\n",
    "    chain = (\n",
    "        ChatPromptTemplate.from_messages(messages)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(inputs)\n",
    "    return answer.split(\"#### \")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your evaluation should look like this:\n",
    "\n",
    "Note: 'exact-match' is the evaluation metric that you have defined in the lunry by yourself."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:35:06.128693Z",
     "start_time": "2024-07-05T19:35:01.057372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score 0.2\n"
     ]
    }
   ],
   "source": [
    "evalset = lunary.get_dataset(\"gsm8k-evalset\")\n",
    "\n",
    "scores = []\n",
    "for item in evalset:\n",
    "    answer = langchain_chain(item.input)\n",
    "    passed, results = lunary.evaluate(\n",
    "        \"exact-match\",\n",
    "        input=item.input,\n",
    "        output=answer,\n",
    "        ideal_output=item.ideal_output.split(\"#### \")[-1],\n",
    "    )\n",
    "    scores.append(int(passed))\n",
    "\n",
    "print(\"Average score\", sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How you should do the few-shot learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rewrite your langchain_chain function to use the `zenbase` decorators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:35:06.308744Z",
     "start_time": "2024-07-05T19:35:06.130258Z"
    }
   },
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest, deflm\n",
    "\n",
    "\n",
    "@deflm\n",
    "def zen_chain(request: LMRequest):\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            (\"user\", demo.inputs),\n",
    "            (\"assistant\", demo.outputs),\n",
    "        ]\n",
    "\n",
    "    messages.append((\"user\", \"{question}\"))\n",
    "\n",
    "    chain = (\n",
    "        ChatPromptTemplate.from_messages(messages)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(request.inputs)\n",
    "    return answer.split(\"#### \")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimize the few-shot learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define your optimizer:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:36:51.783930Z",
     "start_time": "2024-07-05T19:36:33.263871Z"
    }
   },
   "outputs": [],
   "source": [
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "from zenbase.adaptors.lunary import ZenLunary\n",
    "\n",
    "demoset = ZenLunary.dataset_to_demos(lunary.get_dataset(\"gsmk8k-train-set\"))\n",
    "optimizer = LabeledFewShot(demoset=demoset, shots=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform the optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_fn, candidate_results, _ = optimizer.perform(\n",
    "    zen_chain,\n",
    "    evaluator=ZenLunary.metric_evaluator(\n",
    "        checklist=\"exact-match\",\n",
    "        evalset=evalset,\n",
    "        concurrency=5,\n",
    "    ),\n",
    "    samples=4,\n",
    "    rounds=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the best function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:37:22.142816Z",
     "start_time": "2024-07-05T19:37:21.592548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'4'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = best_fn({\"question\": \"What is 2+2?\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the best function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T19:37:23.242695Z",
     "start_time": "2024-07-05T19:37:22.796197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'4'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "zen_chain.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "zen_chain({\"question\": \"What is 2 + 2?\"}) # uses the best few-shot demos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
