{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0caf206d",
   "metadata": {},
   "source": [
    "View the [Loom Walkthrough](https://www.loom.com/embed/f8aedc133e0742519f2837e8718d42c9?sid=942ab16c-e727-4c32-96a7-dbd0ba0abba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e892cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"810\"\n",
       "            height=\"520\"\n",
       "            src=\"https://www.loom.com/embed/f8aedc133e0742519f2837e8718d42c9?sid=942ab16c-e727-4c32-96a7-dbd0ba0abba3\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10f9651e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"https://www.loom.com/embed/f8aedc133e0742519f2837e8718d42c9?sid=942ab16c-e727-4c32-96a7-dbd0ba0abba3\", width=810, height=520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:09.439873Z",
     "start_time": "2024-06-07T21:31:09.429700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "# os.environ[\"PAREA_API_KEY\"] = \"...\"\n",
    "\n",
    "load_dotenv(Path(\"../.env.test\"), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb3ed902652dfd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:10.781718Z",
     "start_time": "2024-06-07T21:31:10.777108Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f32dc5445e19c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:12.061947Z",
     "start_time": "2024-06-07T21:31:11.086702Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from parea import Parea, trace\n",
    "\n",
    "parea = Parea()\n",
    "openai = OpenAI()\n",
    "\n",
    "parea.wrap_openai_client(openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75125e8ad065532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:12.065961Z",
     "start_time": "2024-06-07T21:31:12.063008Z"
    }
   },
   "outputs": [],
   "source": [
    "from parea.schemas import Log, EvaluationResult\n",
    "\n",
    "\n",
    "def score_answer(log: Log) -> EvaluationResult:\n",
    "    if log.target:\n",
    "        output = log.output.split(\"#### \")[-1]\n",
    "        target = log.target.split(\"#### \")[-1]\n",
    "        return EvaluationResult(\"correctness\", int(output == target))\n",
    "\n",
    "\n",
    "@trace(eval_funcs=[score_answer])\n",
    "def langchain_chain(inputs):\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    "\n",
    "    chain = (\n",
    "        ChatPromptTemplate.from_messages(messages)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(inputs)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66675f324975a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:31:36.821496Z",
     "start_time": "2024-06-07T21:31:29.714705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name set to: cushy-jube, since a name was not provided.\n",
      "Fetching test collection: gsm8k-testset\n",
      "Fetched 5 test cases from collection: gsm8k-testset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.11it/s]\n",
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment wibbly-wobbly Run cushy-jube stats:\n",
      "{\n",
      "  \"latency\": \"0.84\",\n",
      "  \"input_tokens\": \"0.00\",\n",
      "  \"output_tokens\": \"0.00\",\n",
      "  \"total_tokens\": \"0.00\",\n",
      "  \"cost\": \"0.00000\",\n",
      "  \"correctness\": \"0.40\"\n",
      "}\n",
      "\n",
      "\n",
      "View experiment & traces at: https://app.parea.ai/experiments/wibbly-wobbly/efcf8e4f-90f3-4c69-993e-c18ca6fa6bd3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_kwargs = dict(\n",
    "    data=\"gsm8k-testset\",\n",
    "    n_workers=2,\n",
    ")\n",
    "\n",
    "parea.experiment(\n",
    "    name=\"wibbly-wobbly\",\n",
    "    func=langchain_chain,\n",
    "    **experiment_kwargs\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35fb30eb084d55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:19.182984Z",
     "start_time": "2024-06-07T21:34:19.178197Z"
    }
   },
   "outputs": [],
   "source": [
    "from zenbase.types import LMRequest, deflm\n",
    "\n",
    "# Step 1: Add the deflm decorator\n",
    "# Step 2: Incorporate few-shot demonstrations\n",
    "\n",
    "@deflm # Step 1\n",
    "@trace(eval_funcs=[score_answer])\n",
    "def zen_chain(request: LMRequest):\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert math solver. Your answer must be just the number with no separators, and nothing else. Follow the format of the examples.\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Step 2\n",
    "    for demo in request.zenbase.task_demos:\n",
    "        messages += [\n",
    "            (\"user\", demo.inputs[\"question\"]),\n",
    "            (\"assistant\", demo.outputs[\"target\"]),\n",
    "        ]\n",
    "\n",
    "    messages.append((\"user\", \"{question}\"))\n",
    "\n",
    "    chain = (\n",
    "        ChatPromptTemplate.from_messages(messages)\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = chain.invoke(request.inputs)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e935c1126e7e18be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:32:11.262370Z",
     "start_time": "2024-06-07T21:31:51.730471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name set to: loved-clip, since a name was not provided.\n",
      "Fetching test collection: gsm8k-testset\n",
      "Fetched 5 test cases from collection: gsm8k-testset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment zenbase-synchronized-mission-critical-website Run loved-clip stats:\n",
      "{\n",
      "  \"latency\": \"1.70\",\n",
      "  \"input_tokens\": \"0.00\",\n",
      "  \"output_tokens\": \"0.00\",\n",
      "  \"total_tokens\": \"0.00\",\n",
      "  \"cost\": \"0.00000\",\n",
      "  \"correctness\": \"0.60\"\n",
      "}\n",
      "\n",
      "\n",
      "View experiment & traces at: https://app.parea.ai/experiments/zenbase-synchronized-mission-critical-website/e931ed2a-33a9-49c1-9e01-248d2e3dcd95\n",
      "\n",
      "Run name set to: paced-kiwi, since a name was not provided.\n",
      "Fetching test collection: gsm8k-testset\n",
      "Fetched 5 test cases from collection: gsm8k-testset \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment zenbase-robust-exuding-adapter Run paced-kiwi stats:\n",
      "{\n",
      "  \"latency\": \"1.65\",\n",
      "  \"input_tokens\": \"0.00\",\n",
      "  \"output_tokens\": \"0.00\",\n",
      "  \"total_tokens\": \"0.00\",\n",
      "  \"cost\": \"0.00000\",\n",
      "  \"correctness\": \"0.60\"\n",
      "}\n",
      "\n",
      "\n",
      "View experiment & traces at: https://app.parea.ai/experiments/zenbase-robust-exuding-adapter/0b3f37bd-3786-4630-8342-0b35efa2579a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zenbase.optim.metric.labeled_few_shot import LabeledFewShot\n",
    "from zenbase.helpers.parea import ZenParea\n",
    "\n",
    "demoset = ZenParea.collection_demos(parea.get_collection(\"gsm8k-demoset\"))\n",
    "optimizer = LabeledFewShot(demoset=demoset, shots=3)\n",
    "\n",
    "best_fn, candidate_results = optimizer.perform(\n",
    "    zen_chain,\n",
    "    evaluator=ZenParea.metric_evaluator(**experiment_kwargs),\n",
    "    samples=2,\n",
    "    rounds=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d03caab067b16ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:32:37.833282Z",
     "start_time": "2024-06-07T21:32:37.303381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = best_fn({\"question\": \"What is 2+2?\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84203be06a032a5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:33:27.644968Z",
     "start_time": "2024-06-07T21:33:25.609472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython autoawait is `on`, and set to use `asyncio`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The shares assigned to me are 30% of 10M = 0.30 * 10M = 3M shares.\\nThe shares assigned to Mamad are 40% of 10M = 0.40 * 10M = 4M shares.\\nSo, the total assigned shares are 3M + 4M = 7M shares.\\nTherefore, the number of unassigned shares is 10M - 7M = 3M shares.\\n#### 3000000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can even run your function asynchronously in a coroutine\n",
    "%autoawait\n",
    "\n",
    "await best_fn.coroutine({\n",
    "    \"question\": \"I have 30 percent of company and Mamad has 40 percent of company and there are 10M shares, how many shares are unassigned?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273ba2abfd65d89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:34:24.204620Z",
     "start_time": "2024-06-07T21:34:23.594362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also save the zenbase params for re-use\n",
    "import pickle\n",
    "\n",
    "pickled_zenbase = pickle.dumps(best_fn.zenbase)\n",
    "zen_chain.zenbase = pickle.loads(pickled_zenbase)\n",
    "\n",
    "zen_chain({\"question\": \"What is 2 + 2?\"}) # uses the best few-shot demos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
